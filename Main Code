import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Load data
data = pd.read_excel('SET DATA.xlsx')
data.head()
# Convert 'AQI Index' to numeric
data['AQI Index'] = pd.to_numeric(data['AQI Index'], errors='coerce')

import seaborn as sns
# Histogram of AQI Index
def plot_histogram(df):
    plt.figure(figsize=(10, 5))
    sns.histplot(df['AQI Index'], bins=30, kde=True, color='blue')
    plt.title('AQI Index Distribution')
    plt.xlabel('AQI Index')
    plt.ylabel('Frequency')
    plt.show()
plot_histogram(data)

# Boxplot for AQI Index
def plot_boxplot(df):
    plt.figure(figsize=(8, 5))
    sns.boxplot(y=df['AQI Index'], color='red',showfliers=True)
    plt.title('AQI Index Boxplot')
    plt.ylabel('AQI Index')
plot_boxplot(data)
print(data.dtypes)

# Check missing values
missing_values = data.isnull().sum()
missing_percentage = (missing_values / len(data)) * 100
print(missing_percentage)

# Drop columns with >30% missing values
columns_to_drop = ['PM10 (µg/m³)', 'NH3 (µg/m³)']
data = data.drop(columns=columns_to_drop)

# Time-series friendly imputation (forward-fill)
data = data.ffill().bfill()  # Fill forward then backward

# Verify no remaining missing values
print(data.isnull().sum())

# Sort index for time-series operations
data = data.sort_index()
# Save cleaned data
data.to_excel('AQI.xlsx')

# Visualization
plt.figure(figsize=(14, 7))
data['AQI Index'].plot(title='AQI Index Trend Over Time', color='darkgreen')
plt.xlabel('Date')
plt.ylabel('AQI Value')
plt.grid(True)
plt.tight_layout()

# Additional analysis (example correlation matrix)
numeric_cols = data.select_dtypes(include=np.number).columns
corr_matrix = data[numeric_cols].corr()
plt.figure(figsize=(10, 8))
plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none')
plt.colorbar()
plt.xticks(range(len(corr_matrix)), corr_matrix.columns, rotation=90)
plt.yticks(range(len(corr_matrix)), corr_matrix.columns)
plt.title('Feature Correlation Matrix')
series = data['AQI Index']
series
print(series.isnull().sum())

# Rolling average for trend
rolling_mean = series.rolling(window=12).mean()
plt.figure(figsize=(8,4))
plt.plot(series, label='Original Series')
plt.plot(rolling_mean, color='red', label='Trend (Rolling Mean)')
plt.legend()

# Assuming 'Date' is a column, not an index
data1 = data.copy()
# Convert the 'Date' column to datetime type if it's not already
data1['Date'] = pd.to_datetime(data1['Date'])
# Extract year and month from the 'Date' column
data1['year'] = data1['Date'].dt.year
data1['month'] = data1['Date'].dt.month_name()

# Reorder the months for plotting
month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
# Plotting the monthly average AQI across years
for month in month_order:
    monthly_data = data1[data1['month'] == month]
    monthly_avg = monthly_data.groupby('year')['AQI Index'].mean()
    # Plot the data
    plt.figure(figsize=(5, 3))
    monthly_avg.plot(kind='line', marker='o', color='b')
    plt.title(f'{month} AQI Across Years')
    plt.xlabel('Year')
    plt.ylabel('Average AQI')

# Calculate the mean AQI for each month
mean_aqi_by_month = data1.groupby('month')['AQI Index'].mean()
# Reorder the months for consistent plotting
mean_aqi_by_month = mean_aqi_by_month.reindex(month_order)

# Calculate the month-to-month change
month_to_month_change = mean_aqi_by_month.diff()
# Set colors based on whether the change is negative (green) or positive (red)
colors = ['green' if x < 0 else 'red' for x in month_to_month_change]
# Plot the month-to-month change in AQI
month_to_month_change.plot(kind='bar', color=colors, figsize=(8, 4))
plt.title('Month-to-Month AQI Change')
plt.xlabel('Month')
plt.ylabel('AQI Change')
plt.axhline(0, color='black', linestyle='--', linewidth=0.8)  # Line at y=0 for reference
plt.xticks(rotation=45)

from statsmodels.tsa.stattools import adfuller
# Perform ADF test
result = adfuller(series)
print('ADF Statistic:', result[0])
print('\np-value:', result[1])
if result[1] < 0.05:
    print("\nThe series is stationary.")
else:
    print("\nThe series is not stationary.")

from pandas.plotting import autocorrelation_plot
autocorrelation_plot(series)
from hurst import compute_Hc
H, c, data2 = compute_Hc(series, kind='change', simplified=True)
print(f"Hurst Exponent: {H}")
if H < 0.5:
    print("\nThe series shows mean-reverting behavior.")
elif H == 0.5:
    print("\nThe series is a random walk.")
    print("\nThe series shows long-term dependence.")
from scipy.stats import linregress
x = range(len(series))
slope, intercept, r_value, p_value, std_err = linregress(x, series)
line = slope * x + intercept
plt.scatter(x, series, label='Data')
plt.plot(x, line, color='red', label='Linear Fit')
print(f"R-squared: {r_value**2}")

from statsmodels.tsa.seasonal import seasonal_decompose
# Decompose the time series
result = seasonal_decompose(series, model='additive', period=365)
result.plot()
from scipy.stats import skew, kurtosis
print(skew(series))
print(kurtosis(series))

import statsmodels.api as sm
from scipy.stats import chi2
from statsmodels.stats.diagnostic import het_arch, linear_reset
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from sklearn.preprocessing import StandardScaler
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Create a simple linear model (used in all tests)
data['Time'] = (data.index - data.index[0]).days  # Days since the first date
X = sm.add_constant(data['Time'])
y = data['AQI Index']
model_null = sm.OLS(y, X).fit()

# 1. McLeod-Li Test for Nonlinearity (ARCH Test)
def mcleod_li_test(model_null):
    residuals = model_null.resid
    arch_test = het_arch(residuals)
    p_value = arch_test[1]
    print(f"McLeod-Li (ARCH) Test p-value: {p_value}")
    if p_value < 0.05:
        print("The test suggests potential nonlinearity (heteroscedasticity).")
        print("No significant evidence of nonlinearity (no heteroscedasticity).")
# 2. Kenan's RESET Test for Nonlinearity
def kenans_reset_test(model_null):
    reset_test = linear_reset(model_null, power=3, test_type='fitted')
    p_value = reset_test.pvalue
    print(f"\nKenan's RESET Test p-value: {p_value}")
    print("The test suggests potential nonlinearity in the model.")
    print("No significant evidence of nonlinearity in the model.")
# 3. Tsay's Test for Nonlinearity (ADF test on residuals)
def tsays_test(model_null):
    def tsay_test_func(residuals):
        adf_stat, p_value, _, _, critical_values, _ = adfuller(residuals)
        return p_value
    residuals_null = model_null.resid
    p_value_tsay = tsay_test_func(residuals_null)
    print(f"\nTsay Test p-value (ADF on residuals): {p_value_tsay}")
    if p_value_tsay < 0.05:
        print("The test suggests nonlinearity in the residuals (structural break or nonstationarity).")
        print("No significant evidence of nonlinearity in the residuals.")
# 4. Likelihood Ratio Test for Threshold Nonlinearity
def likelihood_ratio_test(model_null):
    data['Threshold'] = (data['Time'] > 50).astype(int)  # Define a threshold
    X_complex = sm.add_constant(data[['Time', 'Threshold']])
    model_complex = sm.OLS(y, X_complex).fit()
    log_likelihood_null = model_null.llf  # Log-likelihood of null model
    log_likelihood_complex = model_complex.llf  # Log-likelihood of alternative model
    # Likelihood Ratio Test
    lrt_statistic = -2 * (log_likelihood_null - log_likelihood_complex)
    df = len(model_complex.params) - len(model_null.params)
    p_value_lrt = chi2.sf(lrt_statistic, df)
    print(f"\nLikelihood Ratio Test p-value: {p_value_lrt}")
    if p_value_lrt < 0.05:
        print("The test suggests threshold nonlinearity (better fit with threshold model).")
        print("No significant evidence of threshold nonlinearity.")
# 5. Teresvitas' Neural Network Test for Nonlinearity
def teresvitas_nn_test(data):
    # Standardize the data before feeding it to the neural network
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(data[['Time']])
    y_scaled = data['AQI Index'].values
    # Define the model using Input layer
    nn_model = Sequential([
        Input(shape=(1,)),  # Specify the input shape using Input layer
        Dense(10, activation='relu'),
        Dense(1)
    ])
    nn_model.compile(optimizer='adam', loss='mean_squared_error')
    # Train the neural network
    nn_model.fit(X_scaled, y_scaled, epochs=100, verbose=0)
    # Get predictions from the neural network
    nn_predictions = nn_model.predict(X_scaled)
    # Compare with the linear model predictions
    linear_predictions = model_null.predict(X)
    # Calculate the Mean Squared Error (MSE) of both models
    mse_nn = ((nn_predictions - y_scaled) ** 2).mean()
    mse_linear = ((linear_predictions - y_scaled) ** 2).mean()
    print("\nTeresvitas' Neural Network Test:")
    print(f"Neural Network MSE: {mse_nn}, Linear Model MSE: {mse_linear}")
    if mse_nn < mse_linear:
        print("The neural network model performs better, suggesting nonlinearity.")
        print("The linear model performs better, suggesting linearity.")
# 6. White's Neural Network Test for Nonlinearity
def whites_nn_test(data, model_null):
    # Define a neural network model
    # Calculate residuals from the linear model
    residuals_linear = y_scaled - linear_predictions
    # Calculate the MSE of the residuals from the neural network
    print("\nWhite's Neural Network Test:")
    print(f"Neural Network MSE on residuals: {mse_nn}")
    if mse_nn < ((residuals_linear ** 2).mean()):
        print("The neural network better fits the residuals, suggesting nonlinearity.")
        print("The linear model residuals are better, suggesting linearity.")

# Run all tests
mcleod_li_test(model_null)
kenans_reset_test(model_null)
tsays_test(model_null)
likelihood_ratio_test(model_null)
teresvitas_nn_test(data)
whites_nn_test(data, model_null)

from statsmodels.tsa.arima.model import ARIMA
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler
# Load the data
data = pd.read_excel('AQI.xlsx')
# Assuming 'AQI Index' is the target variable
ts = data['AQI Index']
# Split the data into training and testing sets
train_size = int(len(ts) * 0.8)
train, test = ts[0:train_size], ts[train_size:]
train = train.asfreq('D')
test = test.asfreq('D')
# ARIMA Model
def arima_model(train, test):
    model = ARIMA(train, order=(5,1,0))
    model_fit = model.fit()
    predictions = model_fit.forecast(steps=len(test))
    return predictions
# ARNN Model
def arnn_model(train, test):
    scaler = MinMaxScaler()
    train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))
    test_scaled = scaler.transform(test.values.reshape(-1, 1))
    # Prepare data for ARNN
    def create_dataset(data, look_back=1):
        X, Y = [], []
        for i in range(len(data) - look_back):
            X.append(data[i:(i+look_back), 0])
            Y.append(data[i + look_back, 0])
        return np.array(X), np.array(Y)
    look_back = 1
    trainX, trainY = create_dataset(train_scaled, look_back)
    testX, testY = create_dataset(test_scaled, look_back)
    model = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)
    model.fit(trainX, trainY)
    predictions = model.predict(testX)
    predictions = scaler.inverse_transform(predictions.reshape(-1, 1))
    # Adjust test size to match predictions
    test_adjusted = test.iloc[look_back:]
    return test_adjusted, predictions.flatten()

# ARIMA-ARNN Hybrid Model
def arima_arnn_hybrid(train, test):
    arima_predictions = arima_model(train, test)
    test_adjusted, arnn_predictions = arnn_model(train, test)
    # Combine predictions (simple average)
    hybrid_predictions = (arima_predictions[:len(arnn_predictions)] + arnn_predictions) / 2
    return test_adjusted, hybrid_predictions

# Evaluate models
def evaluate_model(test, predictions, num_features=1):
    mse = mean_squared_error(test, predictions)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(test, predictions)
    mape = np.mean(np.abs((test - predictions) / test)) * 100
    r2 = r2_score(test, predictions)
    # Adjusted R² Calculation
    n = len(test)  # Number of samples
    adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - num_features - 1))
    return rmse, mae, mape, r2, adj_r2

# Fit and evaluate ARIMA
arima_rmse, arima_mae, arima_mape, arima_r2, arima_adj_r2 = evaluate_model(test, arima_predictions)
# Fit and evaluate ARNN
arnn_rmse, arnn_mae, arnn_mape, arnn_r2, arnn_adj_r2 = evaluate_model(test_adjusted, arnn_predictions)
# Fit and evaluate ARIMA-ARNN Hybrid
test_adjusted, hybrid_predictions = arima_arnn_hybrid(train, test)
hybrid_rmse, hybrid_mae, hybrid_mape, hybrid_r2, hybrid_adj_r2 = evaluate_model(test_adjusted, hybrid_predictions)

# Plot ARIMA results
plt.figure(figsize=(10, 6))
plt.plot(test.index, test, label='Actual', color='black')
plt.plot(test.index, arima_predictions, label='ARIMA Predictions', linestyle='dashed', color='blue')
plt.xlabel("Date")
plt.ylabel("AQI Index")
plt.title("AQI Forecasting using ARIMA Model")

# Plot ARNN results
plt.plot(test_adjusted.index, arnn_predictions, label='ARNN Predictions', linestyle='dashed', color='red')
plt.title("AQI Forecasting using ARNN Model")
# Plot ARIMA-ARNN Hybrid results
plt.plot(test_adjusted.index, hybrid_predictions, label='ARIMA-ARNN Hybrid Predictions', linestyle='dashed', color='green')
plt.title("AQI Forecasting using ARIMA-ARNN Hybrid Model")

# Function to print evaluation results neatly
def print_evaluation_results(model_name, rmse, mae, mape, r2, adj_r2):
    print(f"{'-'*60}")
    print(f"{model_name} Model Evaluation Metrics")
    print(f"{'Metric':<20}{'Value'}")
    print(f"{'RMSE':<20}{rmse:.2f}")
    print(f"{'MAE':<20}{mae:.2f}")
    print(f"{'MAPE (%)':<20}{mape:.2f}")
    print(f"{'R²':<20}{r2:.4f}")
    print(f"{'Adjusted R²':<20}{adj_r2:.4f}")
    print(f"{'-'*60}\n")

# Print evaluation results for each model
print_evaluation_results("ARIMA", arima_rmse, arima_mae, arima_mape, arima_r2, arima_adj_r2)
print_evaluation_results("ARNN", arnn_rmse, arnn_mae, arnn_mape, arnn_r2, arnn_adj_r2)
print_evaluation_results("ARIMA-ARNN Hybrid", hybrid_rmse, hybrid_mae, hybrid_mape, hybrid_r2, hybrid_adj_r2)

from sklearn.metrics import mean_squared_error
from tensorflow.keras.layers import LSTM, GRU, Dense, Flatten, Input,SimpleRNN
from tensorflow.keras.optimizers import Adam
from tcn import TCN  # Temporal Convolutional Network
# Load AQI Data
# Convert Date to datetime and set as index
data = data.asfreq('D')  # Ensure daily frequency
# Normalize AQI Values
scaler = MinMaxScaler(feature_range=(0, 1))
data['AQI Index'] = scaler.fit_transform(data[['AQI Index']])
# Split data into train & test sets
train_size = int(len(data) * 0.8)
train, test = data.iloc[:train_size], data.iloc[train_size:]
# Function to create input-output sequences
def create_sequences(data, look_back=5):
        X.append(data[i:i + look_back])
        Y.append(data[i + look_back])
look_back = 5
X_train, Y_train = create_sequences(train['AQI Index'].values, look_back)
X_test, Y_test = create_sequences(test['AQI Index'].values, look_back)
# Reshape for LSTM, GRU, and TCN (samples, timesteps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score
# Function to build & train models with evaluation metrics
def train_model(model, X_train, Y_train, X_test, Y_test, model_name):
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    model.fit(X_train, Y_train, epochs=20, batch_size=16, verbose=1, validation_data=(X_test, Y_test))
    predictions = model.predict(X_test)
    predictions = scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()
    Y_test_actual = scaler.inverse_transform(Y_test.reshape(-1, 1)).flatten()
    # Calculate evaluation metrics
    rmse = np.sqrt(mean_squared_error(Y_test_actual, predictions))
    mae = mean_absolute_error(Y_test_actual, predictions)
    mape = mean_absolute_percentage_error(Y_test_actual, predictions)
    r2 = r2_score(Y_test_actual, predictions)
    n = len(Y_test_actual)
    p = X_train.shape[1]  # Number of predictors
    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)
    # Print evaluation metrics
    print(f'{model_name} Model Evaluation Metrics')
    print('-' * 50)
    print(f'Metric{" " * 15}Value')
    print(f'RMSE{" " * 11}{rmse:.2f}')
    print(f'MAE{" " * 14}{mae:.2f}')
    print(f'MAPE (%){" " * 6}{mape:.2f}')
    print(f'R²{" " * 16}{r2:.4f}')
    print(f'Adjusted R²{" " * 5}{adj_r2:.4f}')
    # Plot results
    plt.plot(test.index[look_back:], Y_test_actual, label='Actual AQI')
    plt.plot(test.index[look_back:], predictions, label=f'{model_name} Predictions')
    plt.title(f'{model_name} AQI Forecast')
# 📌 **1️⃣ LSTM Model**
lstm_model = Sequential([
    Input(shape=(look_back, 1)),  # Explicit Input Layer
    LSTM(50, activation='relu', return_sequences=True),
    LSTM(50, activation='relu'),
train_model(lstm_model, X_train, Y_train, X_test, Y_test, 'LSTM')])
# 📌 **2️⃣ GRU Model**
gru_model = Sequential([
    GRU(50, activation='relu', return_sequences=True),
    GRU(50, activation='relu'),
train_model(gru_model, X_train, Y_train, X_test, Y_test, 'GRU')])
# 📌 **3️⃣ TCN Model**
tcn_model = Sequential([
    TCN(nb_filters=64, kernel_size=2, dilations=[1, 2, 4], return_sequences=True),
    Flatten(),
train_model(tcn_model, X_train, Y_train, X_test, Y_test, 'TCN')])
# 📌 **4️⃣ NARX Model (Using LSTM)**
narx_model = Sequential([
train_model(narx_model, X_train, Y_train, X_test, Y_test, 'NARX-LSTM')])
# 📌 **5️⃣ RNN Model**
rnn_model = Sequential([
    SimpleRNN(50, activation='relu', return_sequences=True),
    SimpleRNN(50, activation='relu'),
train_model(rnn_model, X_train, Y_train, X_test, Y_test, 'RNN')])
